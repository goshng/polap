################################################################################
# This file is part of polap.
#
# polap is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# polap is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# polap. If not, see <https://www.gnu.org/licenses/>.
################################################################################

#!/usr/bin/env bash
# polap-bash-run-data-long.sh
# Normalize a long-read dataset to: $outdir/tmp/l.fq
# Extension priority: .fastq, .fq, .fastq.gz, .fq.gz, .fastq.tar.gz, .fq.tar.gz, -10x.fastq.tar.gz
# Directory order: $PWD first, then --media, --media1, --media2, then remote (if provided).
# Supports optional parallel gzip via pigz for faster (de)compression.

set -euo pipefail

usage() {
  cat <<'EOF'
Usage:
  polap-bash-run-data-long.sh -l <SRA_ID> -o <outdir> [options]

Required:
  -l, --long-sra       SRA accession (e.g., SRR123456)
  -o, --outdir         Output directory (final file: outdir/tmp/l.fq)

Optional:
  --media DIR          First media directory (searched after $PWD)
  --media1 DIR         Second media directory
  --media2 DIR         Third media directory
  -r, --remote HOST    Remote host for ssh/scp (e.g., user@host)
  --prefer-pigz        Prefer pigz for gzip streams (tar -I pigz, pigz -dc)
  -n, --dry-run        Print actions without making changes
  -h, --help           Show this help

Exit codes:
  0  success
  2  usage error
  3  required tool missing
  20 fetch produced no files
  21 fetch failed
  22 normalize failed
EOF
}

# -------- parse args
long_sra=""
outdir=""
media_dir="/media/h2/sra"
media1_dir="/media/h1/sra"
media2_dir="/media/h2/sra"
remote_host="thorne"
dry_run="false"
prefer_pigz="false"

while (("$#")); do
  case "$1" in
    -l|--long-sra) long_sra="${2:?}"; shift 2;;
    -o|--outdir)   outdir="${2:?}";   shift 2;;
    --media)       media_dir="${2:-}"; shift 2;;
    --media1)      media1_dir="${2:-}"; shift 2;;
    --media2)      media2_dir="${2:-}"; shift 2;;
    -r|--remote)   remote_host="${2:-}"; shift 2;;
    --prefer-pigz) prefer_pigz="true"; shift;;
    -n|--dry-run)  dry_run="true"; shift;;
    -h|--help)     usage; exit 0;;
    --) shift; break;;
    -*) echo "Error: Unknown option $1" >&2; usage; exit 2;;
    *)  echo "Error: Unexpected positional $1" >&2; usage; exit 2;;
  esac
done

[[ -n "$long_sra" ]] || { echo "Error: -l|--long-sra is required." >&2; usage; exit 2; }
[[ -n "$outdir"   ]] || { echo "Error: -o|--outdir is required."   >&2; usage; exit 2; }

# -------- paths & helpers
tmpd="${outdir%/}/tmp"
mkdir -p "$tmpd"
norm="${tmpd}/l.fq"
work="${tmpd}/.${long_sra}.work.$$"
mkdir -p "$work"

log()   { printf '[polap-long] %s\n' "$*" >&2; }
maybe() { if [[ "$dry_run" == "true" ]]; then log "(dry-run) $*"; else eval "$@"; fi; }
hr()    { du -h -- "$1" 2>/dev/null | awk '{print $1}'; }

# pick gzip decompressor
gz_cat() {
  if [[ "$prefer_pigz" == "true" ]] && command -v pigz >/dev/null 2>&1; then
    pigz -dc -- "$1"
  else
    gzip -dc -- "$1"
  fi
}

# tar helpers (GNU tar: -I PROG to use pigz)
tar_list_gz() {
  local arc="$1"
  if [[ "$prefer_pigz" == "true" ]] && command -v pigz >/dev/null 2>&1; then
    tar -I pigz -tf -- "$arc"
  else
    tar -tzf -- "$arc"
  fi
}
tar_extract_gz() {
  local arc="$1" dst="$2"
  if [[ "$prefer_pigz" == "true" ]] && command -v pigz >/dev/null 2>&1; then
    maybe "tar -I pigz -xf -- '\$arc' -C '\$dst'"
  else
    maybe "tar -zxf -- '\$arc' -C '\$dst'"
  fi
}

cleanup() { rm -rf -- "$work"; }
trap cleanup EXIT

# ---- OpenSSL mismatch guard ----------------------------------------------
openssl_mismatch_guard() {
  local stderrf="${work}/.stderr.$RANDOM"
  set +e
  "$@" 2>"$stderrf"
  local rc=$?
  set -e
  if ((rc != 0)); then
    if grep -qi 'OpenSSL version mismatch' "$stderrf"; then
      log "WARN(OpenSSL mismatch): $* — skipping this step"
      rm -f "$stderrf"
      return 100
    fi
    cat "$stderrf" >&2
    rm -f "$stderrf"
    return $rc
  fi
  rm -f "$stderrf"
  return 0
}

# -------- normalization helpers
concat_to_norm() {
  # args: files... (mix of .fastq/.fq and gz)
  if [[ "$dry_run" == "true" ]]; then
    log "(dry-run) would concatenate ${#@} file(s) -> $norm"
    return 0
  fi
  : > "$norm"
  local f
  for f in "$@"; do
    case "${f,,}" in
      *.fq|*.fastq)    cat -- "$f" >> "$norm" ;;
      *.fq.gz|*.fastq.gz)
        if [[ "$prefer_pigz" == "true" ]] && command -v pigz >/dev/null 2>&1; then
          pigz -dc -- "$f" >> "$norm"
        else
          gzip -dc -- "$f" >> "$norm"
        fi
        ;;
      *) log "WARN: skipping non-FASTQ file: $f" ;;
    esac
  done
}

emit_from_one_file() {
  # copy/decompress into fixed filename $norm (final name is literally l.fq)
  local src="$1"

  if [[ -f "$src" ]]; then
    log "Source $src size: $(hr "$src")"
  else
    log "WARN: source $src not found"
  fi

  case "${src,,}" in
    *.fq|*.fastq)
      maybe "cat -- '\$src' > '\$norm'"
      ;;
    *.fq.gz|*.fastq.gz)
      log "Decompressing -> $norm ($([[ "$prefer_pigz" == "true" ]] && command -v pigz >/dev/null 2>&1 && echo pigz || echo gzip))"
      if [[ "$dry_run" == "true" ]]; then
        log "(dry-run) would decompress $src -> $norm"
      else
        gz_cat "$src" > "$norm"
      fi
      ;;
    *)
      return 1
      ;;
  esac

  if [[ -f "$norm" ]]; then
    log "Created $norm size: $(hr "$norm")"
  else
    log "WARN: $norm not created"
  fi
}

emit_from_archive() {
  # Extract an archive to $work and concat FASTQs to $norm.
  # Supports: .tar.gz (gzipped tar), .tar (plain), .zip, or single .gz misnamed.
  local apath="$1"
  [[ -f "$apath" ]] || { log "ERROR: archive not found: $apath"; return 1; }

  log "Extracting archive: $apath"
  log "Archive size: $(hr "$apath" || echo '?')"

  local mt; mt="$(file -b --mime-type -- "$apath" 2>/dev/null || true)"
  [[ -z "$mt" ]] && mt="(unknown)"

  if [[ "$dry_run" == "true" ]]; then
    case "$mt" in
      application/gzip|application/x-gzip)
        if tar_list_gz "$apath" >/dev/null 2>&1; then
          local n; n="$(tar_list_gz "$apath" | awk 'BEGIN{IGNORECASE=1} /\.f(ast)?q(\.gz)?$/ {c++} END{print c+0}')"
          log "(dry-run) would extract -> $work ; FASTQ files: $n -> concat -> $norm"
        else
          log "(dry-run) gzip stream not a tarball; would gunzip to FASTQ then concat -> $norm"
        fi
        return 0;;
      application/x-tar)
        if tar -tf -- "$apath" >/dev/null 2>&1; then
          local n; n="$(tar -tf -- "$apath" | awk 'BEGIN{IGNORECASE=1} /\.f(ast)?q(\.gz)?$/ {c++} END{print c+0}')"
          log "(dry-run) would extract -> $work ; FASTQ files: $n -> concat -> $norm"
        else
          log "(dry-run) would try tar -tf/-xf -> $work -> concat -> $norm"
        fi
        return 0;;
      application/zip)
        if unzip -l -- "$apath" >/dev/null 2>&1; then
          local n; n="$(unzip -l -- "$apath" 2>/dev/null | awk 'BEGIN{IGNORECASE=1} /\.f(ast)?q(\.gz)?$/ {c++} END{print c+0}')"
          log "(dry-run) would unzip -> $work ; FASTQ files: $n -> concat -> $norm"
        else
          log "(dry-run) would try unzip -l/-q -> $work -> concat -> $norm"
        fi
        return 0;;
      *) log "(dry-run) unknown mime $mt; would probe tar -tzf → tar -tf → unzip -l"; return 0;;
    esac
  fi

  mkdir -p -- "$work"

  case "$mt" in
    application/gzip|application/x-gzip)
      if ! gzip -t -- "$apath" 2>/dev/null; then
        log "ERROR: gzip integrity check failed: $apath"; return 1
      fi
      if tar_list_gz "$apath" >/dev/null 2>&1; then
        tar_extract_gz "$apath" "$work"
      else
        log "WARN: gzip OK but not a tarball; treating as single gzipped FASTQ"
        local f_out="$work/$(basename "${apath%.tar.gz}").fastq"
        if [[ "$dry_run" == "true" ]]; then
          log "(dry-run) would decompress -> $f_out"
        else
          gz_cat "$apath" > "$f_out"
        fi
      fi
      ;;
    application/x-tar)
      tar -tf -- "$apath" >/dev/null 2>&1 || { log "ERROR: tar list failed: $apath"; return 1; }
      maybe "tar -xf -- '\$apath' -C '\$work'"
      ;;
    application/zip)
      unzip -l -- "$apath" >/dev/null 2>&1 || { log "ERROR: unzip list failed: $apath"; return 1; }
      if [[ "$dry_run" == "true" ]]; then
        log "(dry-run) would unzip -q -- '\$apath' -d '\$work'"
      else
        unzip -q -- "$apath" -d "$work"
      fi
      ;;
    *)
      if tar_list_gz "$apath" >/dev/null 2>&1; then
        tar_extract_gz "$apath" "$work"
      elif tar -tf -- "$apath" >/dev/null 2>&1; then
        maybe "tar -xf -- '\$apath' -C '\$work'"
      elif unzip -l -- "$apath" >/dev/null 2>&1; then
        if [[ "$dry_run" == "true" ]]; then
          log "(dry-run) would unzip -q -- '\$apath' -d '\$work'"
        else
          unzip -q -- "$apath" -d "$work"
        fi
      else
        log "ERROR: unrecognized or unreadable archive: $apath"; return 1
      fi
      ;;
  esac

  mapfile -t files < <(
    find "$work" -type f \( -iname "*.fq" -o -iname "*.fastq" -o -iname "*.fq.gz" -o -iname "*.fastq.gz" \) \
      -print0 | xargs -0 -I{} printf "%s\n" "{}" | sort -V
  )
  ((${#files[@]})) || { log "No FASTQ files found after extraction"; return 1; }

  log "Found ${#files[@]} FASTQ files; concatenating -> $norm"
  concat_to_norm "${files[@]}"

  if [[ -s "$norm" ]]; then
    log "Created $norm size: $(hr "$norm" || echo '?')"
    return 0
  else
    log "❌ Normalized output missing or empty: $norm"
    return 1
  fi
}

# search logic
exts=(
  ".fastq"
  ".fq"
  ".fastq.gz"
  ".fq.gz"
  ".fastq.tar.gz"
  ".fq.tar.gz"
  "-10x.fastq.tar.gz"
)

try_exact_in_dir() {
  local dir="$1" p
  for ext in "${exts[@]}"; do
    p="${dir%/}/${long_sra}${ext}"
    if [[ -s "$p" ]]; then
      log "Found: $p"
      case "${p,,}" in
        *.tar.gz) emit_from_archive "$p" ;;
        *)        emit_from_one_file "$p" ;;
      esac
      return 0
    fi
  done
  return 1
}

try_exact_remote_dir() {
  local dir="$1" rp base local_copy
  [[ -n "$remote_host" ]] || return 1
  for ext in "${exts[@]}"; do
    rp="${dir%/}/${long_sra}${ext}"
    set +e
    openssl_mismatch_guard ssh "$remote_host" "test -s '$rp'"
    local rc=$?
    set -e
    if ((rc == 0)); then
      log "Found remote: ${remote_host}:$rp"
      base="$(basename "$rp")"
      local_copy="${work}/${base}"
      set +e
      openssl_mismatch_guard scp "$remote_host:$rp" "$local_copy"
      rc=$?
      set -e
      if ((rc == 0)); then
        case "${local_copy,,}" in
          *.tar.gz) emit_from_archive "$local_copy" ;;
          *)        emit_from_one_file "$local_copy" ;;
        esac
        return 0
      elif ((rc == 100)); then
        return 1
      else
        continue
      fi
    elif ((rc == 100)); then
      return 1
    fi
  done
  return 1
}

finalize_and_check() {
  if [[ -s "$norm" ]]; then
    log "OK -> $norm"
    printf '%s\n' "$norm"
    return 0
  fi
  log "❌ Normalized output missing or empty: $norm"
  return 22
}

# -------- NCBI fetch (prefetch → vdb-validate → fasterq-dump), guarded
fetch_from_ncbi() {
  log "Fetching from NCBI: $long_sra"
  if [[ "$dry_run" == "true" ]]; then
    log "(dry-run) prefetch '$long_sra' --quiet --max-size u"
    log "(dry-run) vdb-validate '$long_sra' --quiet 2>/dev/null"
    log "(dry-run) fasterq-dump '$long_sra' --quiet 2>/dev/null"
    return 0
  fi

  local rc

  set +e
  openssl_mismatch_guard prefetch "$long_sra" --quiet --max-size u; rc=$?
  set -e
  if ((rc == 100)); then return 20; elif ((rc != 0)); then return 21; fi

  set +e
  openssl_mismatch_guard vdb-validate "$long_sra" --quiet; rc=$?
  set -e
  # proceed even if validation non-zero (not 100)

  set +e
  openssl_mismatch_guard fasterq-dump "$long_sra" --quiet; rc=$?
  set -e
  if ((rc == 100)); then return 20; elif ((rc != 0)); then return 21; fi

  mapfile -t outs < <(find . -maxdepth 1 -type f \( \
    -name "${long_sra}.fastq" -o -name "${long_sra}.fq" -o \
    -name "${long_sra}_1.fastq" -o -name "${long_sra}_2.fastq" -o \
    -name "${long_sra}_1.fq"    -o -name "${long_sra}_2.fq" \
  \) | sed 's#^\./##' | sort -V)

  ((${#outs[@]})) || { log "No FASTQ produced by fasterq-dump."; return 20; }

  concat_to_norm "${outs[@]}"
}

# ==================== MAIN FLOW ====================

# 1) PWD first
if try_exact_in_dir "$PWD"; then finalize_and_check; exit $?; fi

# 2) media dirs (if provided)
for d in "${media_dir:-}" "${media1_dir:-}" "${media2_dir:-}"; do
  [[ -n "$d" ]] || continue
  if try_exact_in_dir "$d"; then finalize_and_check; exit $?; fi
done

# 3) remote (same dir order)
if [[ -n "$remote_host" ]]; then
  for d in "${media_dir:-}" "${media1_dir:-}" "${media2_dir:-}"; do
    [[ -n "$d" ]] || continue
    if try_exact_remote_dir "$d"; then finalize_and_check; exit $?; fi
  done
fi

# 4) fetch from NCBI (guarded)
(
  cd "$work"
  fetch_from_ncbi
)
rc=$?
if ((rc == 0)); then
  finalize_and_check; exit $?
elif ((rc == 20)); then
  log "Fetch skipped or produced no files (likely OpenSSL mismatch)."
  exit 21
else
  log "❌ NCBI fetch failed."
  exit 21
fi
